---
output:
  pdf_document: default
  html_document: default
---
# Discussion {#Discussion} 

The approach in this thesis outlines a way to easily formulate infectious disease compartmental models without having to make unjustified biological assumptions about the underlying disease transmission process in the way that using fixed or parametric models of the transmission rate do. Integrating this into the `macpan2` and `TMB` framework creates for the modeler a user friendly way to fit the model, select the best model and infer estimates of the latent variable at each point in time in the domain. We accomplished this by adapting the general methodology of Simon Wood [@woodPartiallySpecifiedEcological2024] and utilizing it in conjunction with the latter mentioned model formulation tool and optimization engine. 

What we have done differently then the work of Simon Wood is to have made this methodology accessible for a quantitatively minded modeler who may not be an expert in non-linear optimization and smoothing theory. This was made possible because `macpan2` is a driven from a software-engineering perspective. This means that `macpan2` wraps all of the `C++` code needed to interact with `TMB` in an `R` wrapper. It negates the requirement for the modeler to write bespoke optimization code, which can be the biggest hurdle to using such models. 

Through simulation studies, we demonstrated the efficacy of penalized smoothing parameter estimation. The `mgcv` package greatly facilitated the construction of low-rank smoothing bases and penalty matrices for a given domain and model granularity. We compared different smoothing bases, evaluating their performance based on uncertainty estimates, AIC scores, and the shapes of the estimated functions. 

The performance of the semi-mechanistic models to infer the time varying parameters was quite good. We were able to fit the models to the incidence data from the real world examples with the goodness of fit controlled by specifying model granularity and the smoothness by inferring the optimization parameter. We believe these results show that this methodology can be beneficial to any modeler that wishes to estimate a time varying latent variable by inferring the shape of the unknown function. Although we focused on modelling infectious disease with unknown transmission rate and reproduction number, it seems reasonable that it can be applied to an arbitrary compartmental model with some unknown time varying function that one wishes to estimate. This can even be applied to the more general case of dynamic ecological models formulated using compartmental models. 

The models were effective in regards to inference of the fixed parameters. The recovery rate and the initial number of infected individuals were not fixed to to the initial values as is commonly done in most epidemiological studies. Instead, we introduced some flexibility by applying a sharp partial Bayesian log-normal prior. The quantile of this prior was treated as a parameter and calibrated using the data. For future research, a fully Bayesian approach could be adopted by specifying prior distributions for both the mean and variance of the log-normal distribution. This would allow a larger range for the parameter space while possibly not introducing a ton of variance, which occurs when we specify a uninformative prior, i.e, we allow the variance  to become too large.

The relative performance of the different smoothing basis across all examples can be analyzed. In all examples (subsections \ref{simulation}, \ref{scarlet}, \ref{Ireland}, and \ref{Measles}), the Gaussian process (GP) regression smoothing basis proved to be the best in several respects. We observed that the GP basis was the most robust to increases in the effective degrees of freedom when the number of knots was increased. Tables \ref{tab:aic-table-sim}, \ref{tab:aic-table-scarlet}, and \ref{tab:aic-table-ireland} show that during the model fitting procedure, selecting model complexity by adjusting the smoothing parameter \(\lambda\) resulted in a non-significant increase in the conditional AIC score. Checking the resultant effective degrees of freedom for the fitted models across different bases, the GP basis consistently showed the lowest values. This indicates that the GP basis, in conjunction with the `nlminb` optimizer used by `TMB`, is able to find the best smoothing parameter value compared to other bases. For the simulated data, this phenomenon was also observed with the TP, but the TP basis consistently had a conditional AIC score approximately two points lower than the GP basis. It is not clear to us why the difference between the AIC score for the GP and TP basis is constant. However, the uncertainty estimates for the TP basis increased dramatically with model granularity, far more than those for the GP basis. Additionally, across all datasets, the GP basis performed best or near-best. Notably, it was the only model capable of fitting the large Measles dataset. Our conclusion is that, using this methodology, a GP basis is generally an effective choice.

The cyclic basis assumes that the smoothing function takes the same values at the first and last knot for the zeroth and second derivatives. This implies that the shape and height of the function at the beginning and end of a cycle is equivalent. Figures \ref{fig:scarlet_inc} and \ref{fig:ireland_inc} show that the shape of the curve for the observations and the fitted incidence at the beginning and end of the domain are about the same in terms of height and shape. Therefore, it is not surprising that the CC basis fits so well. What is not understood is why the CP and TS bases do not fit well for non-cyclic data, or if using a cyclic basis for these datasets is appropriate. Either way, it is interesting to observe and note this phenomenon regarding cyclic bases.

The effective degrees of the calibrated models are computed as the model degrees of freedom (subsection \ref{Model-comparison-and-selection}). Although the model degrees of freedom take into account the value of the smoothing parameter, it does not take into account the uncertainty estimates of the fitted smoothing parameter. We hypothesize that this may be a part of the reason why there is a constant AIC difference between the GP and TP basis, even though the TP basis tends to have larger uncertainty estimates. From Appendix \ref{AIC}, the effective degrees of freedom is equal to:

\[
\tau = \text{tr}2\mathbb{E}\left[\frac{1}{2} (\hat{\beta} - \beta_K)^T \mathbf{ \mathcal{I}}_K (\hat{\beta} - \beta_K)\right] = \text{tr}  \mathbb{E}[\chi^2_p] = p,
\]

where \(\beta_K\) is the coefficient vector minimizing the K-L divergence and \(\mathbf{ \mathcal{I}}_K\) is the expected negative Hessian of the log likelihood. In [@woodSmoothingParameterModel2016], Wood et al defines the corrected AIC as 

\[
\tau_2 = \text{tr}(\mathbf{V}'_{\beta}\hat{\mathbf{ \mathcal{I}}}),
\]

where \(\mathbf{V}'\) is an approximation of the covariance matrix of the Bayesian large sample approximation 

\[
\beta \mid y,\lambda \sim \mathcal{N}(\hat{\beta}_{\lambda},\mathbf{V}_{\beta})
\]

and \(\mathbf{V}_{\beta} = (\hat{\mathbf{\mathcal{I}}} + \mathbf{P})^{-1}\). \(\hat{\mathbf{ \mathcal{I}}}\) is the is the Hessian of the negative log likelihood at \(\mathbf{ \mathcal{I}}_K\). The goal is to calculate a first-order adjustment to the posterior distribution of the model coefficients, taking into account the uncertainty in the smoothing parameter. After that, the penalty term in the AIC is represented using the Bayesian covariance matrix of the coefficients.

It would be informative, in future work, to compute the corrected AIC for the best fitting models and reevaluate the performance of the smoothing basis. For more complex compartmental models this might be essential as the conditional AIC with the model degrees of freedom is too likely to select a model which includes a random effect that is not present in the true model [@grevenBehaviourMarginalConditional2010]. 

The SIR and SIRS compartmental models we used in this work are very basic compartmental models. Theoretically, a compartmental model can be as complex as the modeler wishes, but in practice, certain assumptions are made to make the fitting process tractable. The models we used are essentially toy examples that allow for a proof of concept of the efficacy of the methodology presented in this thesis. 

In contrast, more realistic compartmental models can be highly complex. They may include numerous compartments (or nodes) and connections (or edges) between them, each with associated parameters or unknown functions that need to be estimated. These models can account for various factors such as different stages of infection, varying rates of transmission, recovery, and immunity, as well as heterogeneity in the population. 

Despite their simplicity, our models effectively demonstrate the potential of the methodology. However, they do not capture the full complexity of real-world scenarios, where the intricate dynamics of disease spread necessitate more sophisticated models. By starting with these simpler models, we can establish a solid foundation for understanding and validating the methodology before potentially extending it to more complicated and realistic compartmental models in future research.

In compartmental models for infectious disease, the response is often assumed to follow a Poisson distribution. This is because the Poisson distribution is well-suited for modeling count data, such as the number of new infection cases within a given time period. However, if the data exhibit overdispersion (i.e., the variance exceeds the mean), a negative binomial distribution might be used instead.

The objective function, as presented in Equation \ref{eq:obj eqn}, assumes that both the observations and the smoothing coefficients are normally distributed. Consequently, when fitting the model to the data, we are essentially performing univariate Gaussian regression with respect to the underlying linear smoother. This assumption simplifies the model for the purpose of demonstrating methodological efficacy. An extension of this approach would be to assume that the observations and the smoothing coefficients follow distributions from the exponential family, such as Poisson or negative binomial distributions. Gu [@chongguSmoothingSplineANOVA2013] describes how to construct the likelihood and penalty functionals for implementing penalized likelihood regression with non-Gaussian responses. 

Assuming the unknown function is linear, as done in this thesis (when the smoother parameter is fixed for each iteration), is a step towards constructing more complex forms of the unknown function. If the modeler wishes to incorporate biological information about the transmission process into the model, they might impose qualitative conditions on the unknown function. For instance, if the unknown function is assumed to be logistic, the modeler can impose specific conditions of non-linearity and boundedness. Extending this methodology to include unknown functional forms other than linear allows the literature to guide the shape of the fitted unknown function by applying qualitative constraints to the smoothing functional. 


In summary, what we have accomplished here is the proof of concept for the ability to estimate time varying unknown functions in deterministic compartmental models. There are many possible avenues of extension, some which we have discussed above. More generally this thesis suggests that it should be possible to be able to adapt this methodology to be used within any optimization framework that fits mixed models by using the theory of the duality of smooths and random effects, to rewrite the smoothing basis as random effects matrices, as we discussed in subsection \ref{The-duality-of-smooths-and-random-effects}. Another avenue of research is to estimate more than one unknown function. All of the methods here are easily extensible to fitting models to data with more than one unknown function, with their own smoothing parameter. Wood [@woodGeneralizedAdditiveModels2017] and Gu [@chongguSmoothingSplineANOVA2013] describe how to formulate models with more than one smoothing parameter. 
